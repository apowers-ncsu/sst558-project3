[
  {
    "objectID": "EDA.html",
    "href": "EDA.html",
    "title": "EDA",
    "section": "",
    "text": "This project explores a dataset, develops models for it, and provides an API interface for on-demand model results. This is one of two Quarto documents; the other is linked at the bottom of this page.\n\n\n\n\nWe are studying data on diabetes health indicators, pulled from Kaggle. The following summaries are from the dataset source page:\n\n\nThe Behavioral Risk Factor Surveillance System (BRFSS) is a health-related telephone survey that is collected annually by the CDC. Each year, the survey collects responses from over 400,000 Americans on health-related risk behaviors, chronic health conditions, and the use of preventative services. It has been conducted every year since 1984. For this project, a csv of the dataset available on Kaggle for the year 2015 was used. This original dataset contains responses from 441,455 individuals and has 330 features. These features are either questions directly asked of participants, or calculated variables based on individual participant responses.\n\n\n\ndiabetes _ binary _ health _ indicators _ BRFSS2015.csv is a clean dataset of 253,680 survey responses to the CDC’s BRFSS2015. The target variable Diabetes_binary has 2 classes. 0 is for no diabetes, and 1 is for prediabetes or diabetes. This dataset has 21 feature variables and is not balanced.\n\n\n\nDiabetes_binary (response variable) 0 = no diabetes 1 = diabetes\nHighBP 0 = no high BP 1 = high BP\nHighChol 0 = no high cholesterol 1 = high cholesterol\nCholCheck 0 = no cholesterol check in 5 years 1 = yes cholesterol check in 5 years\nBMI Body Mass Index\nSmoker Have you smoked at least 100 cigarettes in your entire life? [Note: 5 packs = 100 cigarettes] 0 = no 1 = yes\nStroke (Ever told) you had a stroke. 0 = no 1 = yes\nHeartDiseaseorAttack coronary heart disease (CHD) or myocardial infarction (MI) 0 = no 1 = yes\nPhysActivity physical activity in past 30 days - not including job 0 = no 1 = yes\nFruits Consume Fruit 1 or more times per day 0 = no 1 = yes\nVeggies Consume Vegetables 1 or more times per day 0 = no 1 = yes\nHvyAlcoholConsump (adult men &gt;=14 drinks per week and adult women&gt;=7 drinks per week) 0 = no 1 = yes\nAnyHealthcare Have any kind of health care coverage, including health insurance, prepaid plans such as HMO, etc. 0 = no 1 = yes\nNoDocbcCost Was there a time in the past 12 months when you needed to see a doctor but could not because of cost? 0 = no 1 = yes\nGenHlth Would you say that in general your health is: scale 1-5 1 = excellent 2 = very good 3 = good 4 = fair 5 = poor\nMentHlth days of poor mental health scale 1-30 days\nPhysHlth physical illness or injury days in past 30 days scale 1-30\nDiffWalk Do you have serious difficulty walking or climbing stairs? 0 = no 1 = yes\nSex 0 = female 1 = male\nAge 13-level age category (_AGEG5YR see codebook) scale 1-13 - 1 = 18-24 - 2 = 25-29 - 3 = 30-34 - 4 = 35-39 - 5 = 40-44 - 6 = 45-49 - 7 = 50-54 - 8 = 55-59 - 9 = 60-64 - 10 = 65-69 - 11 = 70-74 - 12 = 75-79 - 13 = 80 or older\nEducation Education level (EDUCA see codebook) scale 1-6 - 1 = Never attended school or only kindergarten - 2 = Grades 1 through 8 (Elementary) - 3 = Grades 9 through 11 (Some high school) - 4 = Grade 12 or GED (High school graduate) - 5 = College 1 year to 3 years (Some college or technical school) - 6 = College 4 years or more (College graduate)\nIncome Income scale (INCOME2 see codebook) scale 1-8 - 1 = less than $10,000 - 2 = Less than $15,000 ($10,000 to less than $15,000) - 3 = Less than $20,000 ($15,000 to less than $20,000) - 4 = Less than $25,000 ($20,000 to less than $25,000) - 5 = Less than $35,000 ($25,000 to less than $35,000) - 6 = Less than $50,000 ($35,000 to less than $50,000) - 7 = Less than $75,000 ($50,000 to less than $75,000) - 8 = $75,000 or more\n\n\n\n\nThere are six components to this project.\n\nEDA - quarto file with EDA (this file)\nModeling - quarto file to select the best model using tidymodels\nAPI - R file fitting the model and defining API structure\nDockerfile - for building the Docker image\n.tar - Docker image\nDemo - video showing me demonstrating my Docker container\n\n\n\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tidymodels)\n\nWarning: package 'tidymodels' was built under R version 4.4.2\n\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.2.0 ──\n✔ broom        1.0.6     ✔ rsample      1.2.1\n✔ dials        1.3.0     ✔ tune         1.2.1\n✔ infer        1.0.7     ✔ workflows    1.1.4\n✔ modeldata    1.4.0     ✔ workflowsets 1.1.0\n✔ parsnip      1.2.1     ✔ yardstick    1.3.1\n✔ recipes      1.1.0     \n\n\nWarning: package 'dials' was built under R version 4.4.2\n\n\nWarning: package 'infer' was built under R version 4.4.2\n\n\nWarning: package 'modeldata' was built under R version 4.4.2\n\n\nWarning: package 'parsnip' was built under R version 4.4.2\n\n\nWarning: package 'recipes' was built under R version 4.4.2\n\n\nWarning: package 'rsample' was built under R version 4.4.2\n\n\nWarning: package 'tune' was built under R version 4.4.2\n\n\nWarning: package 'workflows' was built under R version 4.4.2\n\n\nWarning: package 'workflowsets' was built under R version 4.4.2\n\n\nWarning: package 'yardstick' was built under R version 4.4.2\n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Use tidymodels_prefer() to resolve common conflicts.\n\n\n\n\n\n\nAs typical, let’s conduct standard data cleanup checks, ETL, and other EDA tasks before proceeding to model the data. Although a best practice would be to split the data at hand into a training and testing set first, I’m studying the full data.\n\nmissing or malformed values\nproper data types\nfactoring\ncategorical summaries\nnumeric summaries\n\n\n\nRead the data into our instance, in the variable data.\n\nraw_data &lt;- read_csv(file = 'diabetes_binary_health_indicators_BRFSS2015.csv')\n\nRows: 253680 Columns: 22\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (22): Diabetes_binary, HighBP, HighChol, CholCheck, BMI, Smoker, Stroke,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ndata &lt;- raw_data #saved for backup if needed\n\n\n\n\nCheck for and handle any NA found.\n\nsum_na &lt;- function (column) { sum(is.na(column)) }\ndata |&gt; summarize(across(everything(), sum_na))\n\n# A tibble: 1 × 22\n  Diabetes_binary HighBP HighChol CholCheck   BMI Smoker Stroke\n            &lt;int&gt;  &lt;int&gt;    &lt;int&gt;     &lt;int&gt; &lt;int&gt;  &lt;int&gt;  &lt;int&gt;\n1               0      0        0         0     0      0      0\n# ℹ 15 more variables: HeartDiseaseorAttack &lt;int&gt;, PhysActivity &lt;int&gt;,\n#   Fruits &lt;int&gt;, Veggies &lt;int&gt;, HvyAlcoholConsump &lt;int&gt;, AnyHealthcare &lt;int&gt;,\n#   NoDocbcCost &lt;int&gt;, GenHlth &lt;int&gt;, MentHlth &lt;int&gt;, PhysHlth &lt;int&gt;,\n#   DiffWalk &lt;int&gt;, Sex &lt;int&gt;, Age &lt;int&gt;, Education &lt;int&gt;, Income &lt;int&gt;\n\n\nNone found. Moving on.\n\n\n\nReview the data types auto-assigned to each column. We know that there will be categorical variables identified as numerics, requiring factor updates.\n\nstr(data)\n\nspc_tbl_ [253,680 × 22] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ Diabetes_binary     : num [1:253680] 0 0 0 0 0 0 0 0 1 0 ...\n $ HighBP              : num [1:253680] 1 0 1 1 1 1 1 1 1 0 ...\n $ HighChol            : num [1:253680] 1 0 1 0 1 1 0 1 1 0 ...\n $ CholCheck           : num [1:253680] 1 0 1 1 1 1 1 1 1 1 ...\n $ BMI                 : num [1:253680] 40 25 28 27 24 25 30 25 30 24 ...\n $ Smoker              : num [1:253680] 1 1 0 0 0 1 1 1 1 0 ...\n $ Stroke              : num [1:253680] 0 0 0 0 0 0 0 0 0 0 ...\n $ HeartDiseaseorAttack: num [1:253680] 0 0 0 0 0 0 0 0 1 0 ...\n $ PhysActivity        : num [1:253680] 0 1 0 1 1 1 0 1 0 0 ...\n $ Fruits              : num [1:253680] 0 0 1 1 1 1 0 0 1 0 ...\n $ Veggies             : num [1:253680] 1 0 0 1 1 1 0 1 1 1 ...\n $ HvyAlcoholConsump   : num [1:253680] 0 0 0 0 0 0 0 0 0 0 ...\n $ AnyHealthcare       : num [1:253680] 1 0 1 1 1 1 1 1 1 1 ...\n $ NoDocbcCost         : num [1:253680] 0 1 1 0 0 0 0 0 0 0 ...\n $ GenHlth             : num [1:253680] 5 3 5 2 2 2 3 3 5 2 ...\n $ MentHlth            : num [1:253680] 18 0 30 0 3 0 0 0 30 0 ...\n $ PhysHlth            : num [1:253680] 15 0 30 0 0 2 14 0 30 0 ...\n $ DiffWalk            : num [1:253680] 1 0 1 0 0 0 0 1 1 0 ...\n $ Sex                 : num [1:253680] 0 0 0 0 0 1 0 0 0 1 ...\n $ Age                 : num [1:253680] 9 7 9 11 11 10 9 11 9 8 ...\n $ Education           : num [1:253680] 4 6 4 3 5 6 6 4 5 4 ...\n $ Income              : num [1:253680] 3 1 8 6 4 8 7 4 1 3 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   Diabetes_binary = col_double(),\n  ..   HighBP = col_double(),\n  ..   HighChol = col_double(),\n  ..   CholCheck = col_double(),\n  ..   BMI = col_double(),\n  ..   Smoker = col_double(),\n  ..   Stroke = col_double(),\n  ..   HeartDiseaseorAttack = col_double(),\n  ..   PhysActivity = col_double(),\n  ..   Fruits = col_double(),\n  ..   Veggies = col_double(),\n  ..   HvyAlcoholConsump = col_double(),\n  ..   AnyHealthcare = col_double(),\n  ..   NoDocbcCost = col_double(),\n  ..   GenHlth = col_double(),\n  ..   MentHlth = col_double(),\n  ..   PhysHlth = col_double(),\n  ..   DiffWalk = col_double(),\n  ..   Sex = col_double(),\n  ..   Age = col_double(),\n  ..   Education = col_double(),\n  ..   Income = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\nsummary(data)\n\n Diabetes_binary      HighBP         HighChol        CholCheck     \n Min.   :0.0000   Min.   :0.000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.000   1st Qu.:0.0000   1st Qu.:1.0000  \n Median :0.0000   Median :0.000   Median :0.0000   Median :1.0000  \n Mean   :0.1393   Mean   :0.429   Mean   :0.4241   Mean   :0.9627  \n 3rd Qu.:0.0000   3rd Qu.:1.000   3rd Qu.:1.0000   3rd Qu.:1.0000  \n Max.   :1.0000   Max.   :1.000   Max.   :1.0000   Max.   :1.0000  \n      BMI            Smoker           Stroke        HeartDiseaseorAttack\n Min.   :12.00   Min.   :0.0000   Min.   :0.00000   Min.   :0.00000     \n 1st Qu.:24.00   1st Qu.:0.0000   1st Qu.:0.00000   1st Qu.:0.00000     \n Median :27.00   Median :0.0000   Median :0.00000   Median :0.00000     \n Mean   :28.38   Mean   :0.4432   Mean   :0.04057   Mean   :0.09419     \n 3rd Qu.:31.00   3rd Qu.:1.0000   3rd Qu.:0.00000   3rd Qu.:0.00000     \n Max.   :98.00   Max.   :1.0000   Max.   :1.00000   Max.   :1.00000     \n  PhysActivity        Fruits          Veggies       HvyAlcoholConsump\n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   \n 1st Qu.:1.0000   1st Qu.:0.0000   1st Qu.:1.0000   1st Qu.:0.0000   \n Median :1.0000   Median :1.0000   Median :1.0000   Median :0.0000   \n Mean   :0.7565   Mean   :0.6343   Mean   :0.8114   Mean   :0.0562   \n 3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:0.0000   \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   \n AnyHealthcare     NoDocbcCost         GenHlth         MentHlth     \n Min.   :0.0000   Min.   :0.00000   Min.   :1.000   Min.   : 0.000  \n 1st Qu.:1.0000   1st Qu.:0.00000   1st Qu.:2.000   1st Qu.: 0.000  \n Median :1.0000   Median :0.00000   Median :2.000   Median : 0.000  \n Mean   :0.9511   Mean   :0.08418   Mean   :2.511   Mean   : 3.185  \n 3rd Qu.:1.0000   3rd Qu.:0.00000   3rd Qu.:3.000   3rd Qu.: 2.000  \n Max.   :1.0000   Max.   :1.00000   Max.   :5.000   Max.   :30.000  \n    PhysHlth         DiffWalk           Sex              Age        \n Min.   : 0.000   Min.   :0.0000   Min.   :0.0000   Min.   : 1.000  \n 1st Qu.: 0.000   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.: 6.000  \n Median : 0.000   Median :0.0000   Median :0.0000   Median : 8.000  \n Mean   : 4.242   Mean   :0.1682   Mean   :0.4403   Mean   : 8.032  \n 3rd Qu.: 3.000   3rd Qu.:0.0000   3rd Qu.:1.0000   3rd Qu.:10.000  \n Max.   :30.000   Max.   :1.0000   Max.   :1.0000   Max.   :13.000  \n   Education        Income     \n Min.   :1.00   Min.   :1.000  \n 1st Qu.:4.00   1st Qu.:5.000  \n Median :5.00   Median :7.000  \n Mean   :5.05   Mean   :6.054  \n 3rd Qu.:6.00   3rd Qu.:8.000  \n Max.   :6.00   Max.   :8.000  \n\n\nWe need to factor many of these fields. I also like to change doubles to integers for appropriate numeric fields. I checked the summary() to confirm that categorical variables like Age do not have values outside of the known ranges.\n\n\nFirst, factoring the simple ones with only a 0/1, then the batch of larger categorical fields.\n\n#simple factors first\ndata &lt;- data |&gt; mutate(\n  Diabetes_binary = factor(Diabetes_binary,labels=c(\"not diabetic\",\"diabetic\")),\n  HighBP = factor(HighBP,labels=c(\"no high blood pressure\",\"high blood pressure\")),\n  HighChol = factor(HighChol,labels=c(\"no high cholesterol\",\"high cholesterol\")),\n  CholCheck = factor(CholCheck,labels=c(\"no recent cholesterol check\",\"recent cholesterol check\")),\n  Smoker = factor(Smoker,labels=c(\"non-smoker\",\"smoker\")),\n  Stroke = factor(Stroke,labels=c(\"no stroke\",\"stroke\")),\n  HeartDiseaseorAttack = factor(HeartDiseaseorAttack,labels=c(\"no heart problems CHD/MI\",\"heart problems CHD/MI\")),\n  PhysActivity = factor(PhysActivity,labels=c(\"no physical activity\",\"physical activity\")),\n  Fruits = factor(Fruits,labels=c(\"no fruits\",\"fruits\")),\n  Veggies = factor(Veggies,labels=c(\"no vegetables\",\"vegetables\")),\n  HvyAlcoholConsump = factor(HvyAlcoholConsump,labels=c(\"no heavy alcohol\",\"heavy alcohol\")),\n  AnyHealthcare = factor(AnyHealthcare,labels=c(\"no healthcare\",\"healthcare\")),\n  NoDocbcCost = factor(NoDocbcCost,labels=c(\"not avoided doctor for cost\",\"avoided doctor for cost\")),\n  DiffWalk = factor(DiffWalk,labels=c(\"no walking difficulty\",\"walking difficulty\")),\n  Sex = factor(Sex,labels=c(\"female\",\"male\"))\n)\n\n#larger categories\ndata &lt;- data |&gt; mutate(\n  GenHlth = factor(GenHlth,labels=c(\"excellent\",\"very good\",\"good\",\"fair\",\"poor\")),\n  Age = factor(Age,labels=c(\n    \"18-24\",\n    \"25-29\",\n    \"30-34\",\n    \"35-39\",\n    \"40-44\",\n    \"45-49\",\n    \"50-54\",\n    \"55-59\",\n    \"60-64\",\n    \"65-69\",\n    \"70-74\",\n    \"75-79\",\n    \"80+\")),\n  Education = factor(Education,labels=c(\n    \"Never attended school or only kindergarten\",\n    \"Grades 1-8 (Elementary)\",\n    \"Grades 9-11 (Some high school)\",\n    \"Grades 12 or GED (High school graduate)\",\n    \"College 1-3 years (Some college or technical school\",\n    \"College 4+ years (College graduate)\")),\n  Income = factor(Income,labels=c(\n    \"[ - $10k)\",\n    \"[$10k - $15k)\",\n    \"[$15k - $20k)\",\n    \"[$20k - $25k)\",\n    \"[$25k - $35k)\",\n    \"[$35k - $50k)\",\n    \"[$50k - $75k)\",\n    \"[$75k - ]\"))\n)\n\n\n\n\nTransitioning from double to integers where needed. Checking values to confirm integers appropriate before switch.\n\n#checking results for integer reasonableness\nunique(data$BMI)\n\n [1] 40 25 28 27 24 30 34 26 33 21 23 22 38 32 37 31 29 20 35 45 39 19 47 18 36\n[26] 43 55 49 42 17 16 41 44 50 59 48 52 46 54 57 53 14 15 51 58 63 61 56 74 62\n[51] 64 66 73 85 60 67 65 70 82 79 92 68 72 88 96 13 81 71 75 12 77 69 76 87 89\n[76] 84 95 98 91 86 83 80 90 78\n\nunique(data$MentHlth)\n\n [1] 18  0 30  3  5 15 10  6 20  2 25  1  4  7  8 21 14 26 29 16 28 11 12 24 17\n[26] 13 27 19 22  9 23\n\nunique(data$PhysHlth)\n\n [1] 15  0 30  2 14 28  7 20  3 10  1  5 17  4 19  6 12 25 27 21 22  8 29 24  9\n[26] 16 18 23 13 26 11\n\n#convert doubles to ints\ndata &lt;- data |&gt; mutate(\n  BMI = as.integer(BMI),\n  MentHlth = as.integer(MentHlth),\n  PhysHlth = as.integer(PhysHlth)\n)\n\nstr(data)\n\ntibble [253,680 × 22] (S3: tbl_df/tbl/data.frame)\n $ Diabetes_binary     : Factor w/ 2 levels \"not diabetic\",..: 1 1 1 1 1 1 1 1 2 1 ...\n $ HighBP              : Factor w/ 2 levels \"no high blood pressure\",..: 2 1 2 2 2 2 2 2 2 1 ...\n $ HighChol            : Factor w/ 2 levels \"no high cholesterol\",..: 2 1 2 1 2 2 1 2 2 1 ...\n $ CholCheck           : Factor w/ 2 levels \"no recent cholesterol check\",..: 2 1 2 2 2 2 2 2 2 2 ...\n $ BMI                 : int [1:253680] 40 25 28 27 24 25 30 25 30 24 ...\n $ Smoker              : Factor w/ 2 levels \"non-smoker\",\"smoker\": 2 2 1 1 1 2 2 2 2 1 ...\n $ Stroke              : Factor w/ 2 levels \"no stroke\",\"stroke\": 1 1 1 1 1 1 1 1 1 1 ...\n $ HeartDiseaseorAttack: Factor w/ 2 levels \"no heart problems CHD/MI\",..: 1 1 1 1 1 1 1 1 2 1 ...\n $ PhysActivity        : Factor w/ 2 levels \"no physical activity\",..: 1 2 1 2 2 2 1 2 1 1 ...\n $ Fruits              : Factor w/ 2 levels \"no fruits\",\"fruits\": 1 1 2 2 2 2 1 1 2 1 ...\n $ Veggies             : Factor w/ 2 levels \"no vegetables\",..: 2 1 1 2 2 2 1 2 2 2 ...\n $ HvyAlcoholConsump   : Factor w/ 2 levels \"no heavy alcohol\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ AnyHealthcare       : Factor w/ 2 levels \"no healthcare\",..: 2 1 2 2 2 2 2 2 2 2 ...\n $ NoDocbcCost         : Factor w/ 2 levels \"not avoided doctor for cost\",..: 1 2 2 1 1 1 1 1 1 1 ...\n $ GenHlth             : Factor w/ 5 levels \"excellent\",\"very good\",..: 5 3 5 2 2 2 3 3 5 2 ...\n $ MentHlth            : int [1:253680] 18 0 30 0 3 0 0 0 30 0 ...\n $ PhysHlth            : int [1:253680] 15 0 30 0 0 2 14 0 30 0 ...\n $ DiffWalk            : Factor w/ 2 levels \"no walking difficulty\",..: 2 1 2 1 1 1 1 2 2 1 ...\n $ Sex                 : Factor w/ 2 levels \"female\",\"male\": 1 1 1 1 1 2 1 1 1 2 ...\n $ Age                 : Factor w/ 13 levels \"18-24\",\"25-29\",..: 9 7 9 11 11 10 9 11 9 8 ...\n $ Education           : Factor w/ 6 levels \"Never attended school or only kindergarten\",..: 4 6 4 3 5 6 6 4 5 4 ...\n $ Income              : Factor w/ 8 levels \"[ - $10k)\",\"[$10k - $15k)\",..: 3 1 8 6 4 8 7 4 1 3 ...\n\n\n\n\n\n\nMaking a few exploratory charts and plots, to increase understanding of the data and explore hunches and questions.\n\n\nThis section explores a few categorical variables with contingency tables and bar plots.\nWhat is our distribution of failures and successes (Diabetes_binary)?\n\ndata |&gt; \n  group_by(Diabetes_binary) |&gt;\n  summarize(count = n())\n\n# A tibble: 2 × 2\n  Diabetes_binary  count\n  &lt;fct&gt;            &lt;int&gt;\n1 not diabetic    218334\n2 diabetic         35346\n\n\nAbout 7:1 non-diabetic vs diabetic, with satisfactory sample sizes.\nLet’s explore the sex and age makeups. I’m switching to plots because I find the tabular, numeric contingency data to be less informative for exploration.\n\ng &lt;- data |&gt;\n  ggplot(\n    aes(\n      x=Age\n    )\n  ) +\n  labs(\n    title=\"Age Group Representation\"\n  ) +\n  geom_bar(\n    \n  )\ng\n\n\n\n\n\n\n\n\nMost in their 50-60s, generally older subjects.\n\ng &lt;- data |&gt;\n  ggplot(\n    aes(\n      x=Age,\n      fill=Sex\n    )\n  ) +\n  labs(\n    title=\"Age Group Representation by Sex\"\n  ) +\n  geom_bar(\n\n  )\ng\n\n\n\n\n\n\n\n\nReasonably equal makeup of men and women across age groups. How about the same faceted across income levels?\n\ng &lt;- data |&gt;\n  ggplot(\n    aes(\n      x=Age,\n      fill=Sex\n    )\n  ) +\n  labs(\n    title=\"Age Group Representation by Sex faceted by Income\",\n    x=''\n  ) +\n  geom_bar(\n\n  ) +\n  facet_grid(\n    . ~ Income\n  ) +\n  theme(\n    axis.text.x=element_blank()\n  )\ng\n\n\n\n\n\n\n\n\nOur survey data leans heavily on middle class+ respondents. It’s worth recalling this as interpretations are made in aggregate, either to temper them with a known skew toward high earners or else grouped by income levels as a known strata of interest. Then again, this variable may have no significant bearing on the predictive model, in which case this point is unnecessary.\nLet’s adjust this to see diabetic state by income level.\n\ng &lt;- data |&gt;\n  ggplot(\n    aes(\n      x=Age,\n      fill=Diabetes_binary\n    )\n  ) +\n  labs(\n    title=\"Age Group Representation by Diabetes state faceted by Income\",\n    x=''\n  ) +\n  geom_bar(\n\n  ) +\n  facet_grid(\n    . ~ Income\n  ) +\n  theme(\n    axis.text.x=element_blank()\n  )\ng\n\n\n\n\n\n\n\n\nAt a glance, I think the proportion of diabetic respondents is higher for lower income levels. Interesting but no takeaway right now.\n\n\n\nWe have three numeric fields to explore: BMI, Mental Health, and Physical Health. The encoding here is a little confusing, where higher numbers indicate more detrimental values of BMI, mental, or physical health. The two health fields are a count of problems experienced in the last X days.\nFirst, let’s check density charts for Diabetic and non-Diabetic fills.\n\ng &lt;- data |&gt;\n  ggplot(\n    aes(\n      x=BMI,\n      fill=Diabetes_binary\n    )\n  ) +\n  labs(\n    title=\"BMI density chart with Diabetes state\",\n  ) +\n  geom_density(\n    alpha=0.5\n    #bindwidth=11\n  ) \ng\n\n\n\n\n\n\n\n\nThat is staggeringly clear, a strong predictor.\n\ng &lt;- data |&gt; ggplot()\ng +\n  aes(\n    x=MentHlth,\n    fill=Diabetes_binary\n  ) +\n  labs(\n    title=\"Mental Health Incidents Histogram with Diabetes state\",\n  ) +\n  geom_histogram(\n    alpha=0.5,\n    binwidth=2\n  ) \n\n\n\n\n\n\n\n\n\ng &lt;- data |&gt; ggplot()\ng +\n  aes(\n    x=PhysHlth,\n    fill=Diabetes_binary\n  ) +\n  labs(\n    title=\"Physical Health Incidents Histogram with Diabetes state\",\n  ) +\n  geom_histogram(\n    alpha=0.5,\n    binwidth=2\n  ) \n\n\n\n\n\n\n\n\nThese health numeric variables are skewed heavily right, with most respondents reporting 0. I don’t expect much to come from it but let’s check summaries and correlation too.\n\ndata |&gt; \n  select(BMI,MentHlth,PhysHlth) |&gt;\n  summary()\n\n      BMI           MentHlth         PhysHlth     \n Min.   :12.00   Min.   : 0.000   Min.   : 0.000  \n 1st Qu.:24.00   1st Qu.: 0.000   1st Qu.: 0.000  \n Median :27.00   Median : 0.000   Median : 0.000  \n Mean   :28.38   Mean   : 3.185   Mean   : 4.242  \n 3rd Qu.:31.00   3rd Qu.: 2.000   3rd Qu.: 3.000  \n Max.   :98.00   Max.   :30.000   Max.   :30.000  \n\n\n\ncor(data[sapply(data,is.numeric)]) \n\n                BMI   MentHlth  PhysHlth\nBMI      1.00000000 0.08531016 0.1211411\nMentHlth 0.08531016 1.00000000 0.3536189\nPhysHlth 0.12114111 0.35361887 1.0000000\n\n\nThe summary stats confirm the takes noted above. Stronger correlation between mental health incident days and physical health incident days, which sounds reasonable. No need to explore a scatterplot here, for these few and clear numeric variables.\nInstead, let’s check a boxplot of the numeric fields across categories including the response variable.\n\ng &lt;- data |&gt; ggplot()\ng +\n  aes(\n\n  ) +\n  labs(\n    title=\"BMI over Diabetes state by Sex\",\n  ) +\n  geom_boxplot(\n    aes(\n      x=BMI,\n      fill=Diabetes_binary\n      )  \n    ) +\n  facet_grid( Sex~.)\n\n\n\n\n\n\n\n\nSo, higher BMIs link with diabetic state in both sexes. Also, interesting to see the range of BMI for diabetic females is a little wider than that of males.\nDone with EDA here. I think many of the predictors may relate to the response variable, so I’ll proceed to modeling to understand more about the stronger predictor variables, then perhaps study further. I’ll save and load the updated tibble with my data for processing in the Modeling page.\nClick here for the Modeling Page\n\n#here, just saving data frame for use in Modeling\nsave(data,file=\"data.RData\")"
  },
  {
    "objectID": "EDA.html#project-introduction",
    "href": "EDA.html#project-introduction",
    "title": "EDA",
    "section": "",
    "text": "We are studying data on diabetes health indicators, pulled from Kaggle. The following summaries are from the dataset source page:\n\n\nThe Behavioral Risk Factor Surveillance System (BRFSS) is a health-related telephone survey that is collected annually by the CDC. Each year, the survey collects responses from over 400,000 Americans on health-related risk behaviors, chronic health conditions, and the use of preventative services. It has been conducted every year since 1984. For this project, a csv of the dataset available on Kaggle for the year 2015 was used. This original dataset contains responses from 441,455 individuals and has 330 features. These features are either questions directly asked of participants, or calculated variables based on individual participant responses.\n\n\n\ndiabetes _ binary _ health _ indicators _ BRFSS2015.csv is a clean dataset of 253,680 survey responses to the CDC’s BRFSS2015. The target variable Diabetes_binary has 2 classes. 0 is for no diabetes, and 1 is for prediabetes or diabetes. This dataset has 21 feature variables and is not balanced.\n\n\n\nDiabetes_binary (response variable) 0 = no diabetes 1 = diabetes\nHighBP 0 = no high BP 1 = high BP\nHighChol 0 = no high cholesterol 1 = high cholesterol\nCholCheck 0 = no cholesterol check in 5 years 1 = yes cholesterol check in 5 years\nBMI Body Mass Index\nSmoker Have you smoked at least 100 cigarettes in your entire life? [Note: 5 packs = 100 cigarettes] 0 = no 1 = yes\nStroke (Ever told) you had a stroke. 0 = no 1 = yes\nHeartDiseaseorAttack coronary heart disease (CHD) or myocardial infarction (MI) 0 = no 1 = yes\nPhysActivity physical activity in past 30 days - not including job 0 = no 1 = yes\nFruits Consume Fruit 1 or more times per day 0 = no 1 = yes\nVeggies Consume Vegetables 1 or more times per day 0 = no 1 = yes\nHvyAlcoholConsump (adult men &gt;=14 drinks per week and adult women&gt;=7 drinks per week) 0 = no 1 = yes\nAnyHealthcare Have any kind of health care coverage, including health insurance, prepaid plans such as HMO, etc. 0 = no 1 = yes\nNoDocbcCost Was there a time in the past 12 months when you needed to see a doctor but could not because of cost? 0 = no 1 = yes\nGenHlth Would you say that in general your health is: scale 1-5 1 = excellent 2 = very good 3 = good 4 = fair 5 = poor\nMentHlth days of poor mental health scale 1-30 days\nPhysHlth physical illness or injury days in past 30 days scale 1-30\nDiffWalk Do you have serious difficulty walking or climbing stairs? 0 = no 1 = yes\nSex 0 = female 1 = male\nAge 13-level age category (_AGEG5YR see codebook) scale 1-13 - 1 = 18-24 - 2 = 25-29 - 3 = 30-34 - 4 = 35-39 - 5 = 40-44 - 6 = 45-49 - 7 = 50-54 - 8 = 55-59 - 9 = 60-64 - 10 = 65-69 - 11 = 70-74 - 12 = 75-79 - 13 = 80 or older\nEducation Education level (EDUCA see codebook) scale 1-6 - 1 = Never attended school or only kindergarten - 2 = Grades 1 through 8 (Elementary) - 3 = Grades 9 through 11 (Some high school) - 4 = Grade 12 or GED (High school graduate) - 5 = College 1 year to 3 years (Some college or technical school) - 6 = College 4 years or more (College graduate)\nIncome Income scale (INCOME2 see codebook) scale 1-8 - 1 = less than $10,000 - 2 = Less than $15,000 ($10,000 to less than $15,000) - 3 = Less than $20,000 ($15,000 to less than $20,000) - 4 = Less than $25,000 ($20,000 to less than $25,000) - 5 = Less than $35,000 ($25,000 to less than $35,000) - 6 = Less than $50,000 ($35,000 to less than $50,000) - 7 = Less than $75,000 ($50,000 to less than $75,000) - 8 = $75,000 or more\n\n\n\n\nThere are six components to this project.\n\nEDA - quarto file with EDA (this file)\nModeling - quarto file to select the best model using tidymodels\nAPI - R file fitting the model and defining API structure\nDockerfile - for building the Docker image\n.tar - Docker image\nDemo - video showing me demonstrating my Docker container\n\n\n\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tidymodels)\n\nWarning: package 'tidymodels' was built under R version 4.4.2\n\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.2.0 ──\n✔ broom        1.0.6     ✔ rsample      1.2.1\n✔ dials        1.3.0     ✔ tune         1.2.1\n✔ infer        1.0.7     ✔ workflows    1.1.4\n✔ modeldata    1.4.0     ✔ workflowsets 1.1.0\n✔ parsnip      1.2.1     ✔ yardstick    1.3.1\n✔ recipes      1.1.0     \n\n\nWarning: package 'dials' was built under R version 4.4.2\n\n\nWarning: package 'infer' was built under R version 4.4.2\n\n\nWarning: package 'modeldata' was built under R version 4.4.2\n\n\nWarning: package 'parsnip' was built under R version 4.4.2\n\n\nWarning: package 'recipes' was built under R version 4.4.2\n\n\nWarning: package 'rsample' was built under R version 4.4.2\n\n\nWarning: package 'tune' was built under R version 4.4.2\n\n\nWarning: package 'workflows' was built under R version 4.4.2\n\n\nWarning: package 'workflowsets' was built under R version 4.4.2\n\n\nWarning: package 'yardstick' was built under R version 4.4.2\n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Use tidymodels_prefer() to resolve common conflicts."
  },
  {
    "objectID": "EDA.html#eda",
    "href": "EDA.html#eda",
    "title": "EDA",
    "section": "",
    "text": "As typical, let’s conduct standard data cleanup checks, ETL, and other EDA tasks before proceeding to model the data. Although a best practice would be to split the data at hand into a training and testing set first, I’m studying the full data.\n\nmissing or malformed values\nproper data types\nfactoring\ncategorical summaries\nnumeric summaries\n\n\n\nRead the data into our instance, in the variable data.\n\nraw_data &lt;- read_csv(file = 'diabetes_binary_health_indicators_BRFSS2015.csv')\n\nRows: 253680 Columns: 22\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (22): Diabetes_binary, HighBP, HighChol, CholCheck, BMI, Smoker, Stroke,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ndata &lt;- raw_data #saved for backup if needed\n\n\n\n\nCheck for and handle any NA found.\n\nsum_na &lt;- function (column) { sum(is.na(column)) }\ndata |&gt; summarize(across(everything(), sum_na))\n\n# A tibble: 1 × 22\n  Diabetes_binary HighBP HighChol CholCheck   BMI Smoker Stroke\n            &lt;int&gt;  &lt;int&gt;    &lt;int&gt;     &lt;int&gt; &lt;int&gt;  &lt;int&gt;  &lt;int&gt;\n1               0      0        0         0     0      0      0\n# ℹ 15 more variables: HeartDiseaseorAttack &lt;int&gt;, PhysActivity &lt;int&gt;,\n#   Fruits &lt;int&gt;, Veggies &lt;int&gt;, HvyAlcoholConsump &lt;int&gt;, AnyHealthcare &lt;int&gt;,\n#   NoDocbcCost &lt;int&gt;, GenHlth &lt;int&gt;, MentHlth &lt;int&gt;, PhysHlth &lt;int&gt;,\n#   DiffWalk &lt;int&gt;, Sex &lt;int&gt;, Age &lt;int&gt;, Education &lt;int&gt;, Income &lt;int&gt;\n\n\nNone found. Moving on.\n\n\n\nReview the data types auto-assigned to each column. We know that there will be categorical variables identified as numerics, requiring factor updates.\n\nstr(data)\n\nspc_tbl_ [253,680 × 22] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ Diabetes_binary     : num [1:253680] 0 0 0 0 0 0 0 0 1 0 ...\n $ HighBP              : num [1:253680] 1 0 1 1 1 1 1 1 1 0 ...\n $ HighChol            : num [1:253680] 1 0 1 0 1 1 0 1 1 0 ...\n $ CholCheck           : num [1:253680] 1 0 1 1 1 1 1 1 1 1 ...\n $ BMI                 : num [1:253680] 40 25 28 27 24 25 30 25 30 24 ...\n $ Smoker              : num [1:253680] 1 1 0 0 0 1 1 1 1 0 ...\n $ Stroke              : num [1:253680] 0 0 0 0 0 0 0 0 0 0 ...\n $ HeartDiseaseorAttack: num [1:253680] 0 0 0 0 0 0 0 0 1 0 ...\n $ PhysActivity        : num [1:253680] 0 1 0 1 1 1 0 1 0 0 ...\n $ Fruits              : num [1:253680] 0 0 1 1 1 1 0 0 1 0 ...\n $ Veggies             : num [1:253680] 1 0 0 1 1 1 0 1 1 1 ...\n $ HvyAlcoholConsump   : num [1:253680] 0 0 0 0 0 0 0 0 0 0 ...\n $ AnyHealthcare       : num [1:253680] 1 0 1 1 1 1 1 1 1 1 ...\n $ NoDocbcCost         : num [1:253680] 0 1 1 0 0 0 0 0 0 0 ...\n $ GenHlth             : num [1:253680] 5 3 5 2 2 2 3 3 5 2 ...\n $ MentHlth            : num [1:253680] 18 0 30 0 3 0 0 0 30 0 ...\n $ PhysHlth            : num [1:253680] 15 0 30 0 0 2 14 0 30 0 ...\n $ DiffWalk            : num [1:253680] 1 0 1 0 0 0 0 1 1 0 ...\n $ Sex                 : num [1:253680] 0 0 0 0 0 1 0 0 0 1 ...\n $ Age                 : num [1:253680] 9 7 9 11 11 10 9 11 9 8 ...\n $ Education           : num [1:253680] 4 6 4 3 5 6 6 4 5 4 ...\n $ Income              : num [1:253680] 3 1 8 6 4 8 7 4 1 3 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   Diabetes_binary = col_double(),\n  ..   HighBP = col_double(),\n  ..   HighChol = col_double(),\n  ..   CholCheck = col_double(),\n  ..   BMI = col_double(),\n  ..   Smoker = col_double(),\n  ..   Stroke = col_double(),\n  ..   HeartDiseaseorAttack = col_double(),\n  ..   PhysActivity = col_double(),\n  ..   Fruits = col_double(),\n  ..   Veggies = col_double(),\n  ..   HvyAlcoholConsump = col_double(),\n  ..   AnyHealthcare = col_double(),\n  ..   NoDocbcCost = col_double(),\n  ..   GenHlth = col_double(),\n  ..   MentHlth = col_double(),\n  ..   PhysHlth = col_double(),\n  ..   DiffWalk = col_double(),\n  ..   Sex = col_double(),\n  ..   Age = col_double(),\n  ..   Education = col_double(),\n  ..   Income = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\nsummary(data)\n\n Diabetes_binary      HighBP         HighChol        CholCheck     \n Min.   :0.0000   Min.   :0.000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.000   1st Qu.:0.0000   1st Qu.:1.0000  \n Median :0.0000   Median :0.000   Median :0.0000   Median :1.0000  \n Mean   :0.1393   Mean   :0.429   Mean   :0.4241   Mean   :0.9627  \n 3rd Qu.:0.0000   3rd Qu.:1.000   3rd Qu.:1.0000   3rd Qu.:1.0000  \n Max.   :1.0000   Max.   :1.000   Max.   :1.0000   Max.   :1.0000  \n      BMI            Smoker           Stroke        HeartDiseaseorAttack\n Min.   :12.00   Min.   :0.0000   Min.   :0.00000   Min.   :0.00000     \n 1st Qu.:24.00   1st Qu.:0.0000   1st Qu.:0.00000   1st Qu.:0.00000     \n Median :27.00   Median :0.0000   Median :0.00000   Median :0.00000     \n Mean   :28.38   Mean   :0.4432   Mean   :0.04057   Mean   :0.09419     \n 3rd Qu.:31.00   3rd Qu.:1.0000   3rd Qu.:0.00000   3rd Qu.:0.00000     \n Max.   :98.00   Max.   :1.0000   Max.   :1.00000   Max.   :1.00000     \n  PhysActivity        Fruits          Veggies       HvyAlcoholConsump\n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   \n 1st Qu.:1.0000   1st Qu.:0.0000   1st Qu.:1.0000   1st Qu.:0.0000   \n Median :1.0000   Median :1.0000   Median :1.0000   Median :0.0000   \n Mean   :0.7565   Mean   :0.6343   Mean   :0.8114   Mean   :0.0562   \n 3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:0.0000   \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   \n AnyHealthcare     NoDocbcCost         GenHlth         MentHlth     \n Min.   :0.0000   Min.   :0.00000   Min.   :1.000   Min.   : 0.000  \n 1st Qu.:1.0000   1st Qu.:0.00000   1st Qu.:2.000   1st Qu.: 0.000  \n Median :1.0000   Median :0.00000   Median :2.000   Median : 0.000  \n Mean   :0.9511   Mean   :0.08418   Mean   :2.511   Mean   : 3.185  \n 3rd Qu.:1.0000   3rd Qu.:0.00000   3rd Qu.:3.000   3rd Qu.: 2.000  \n Max.   :1.0000   Max.   :1.00000   Max.   :5.000   Max.   :30.000  \n    PhysHlth         DiffWalk           Sex              Age        \n Min.   : 0.000   Min.   :0.0000   Min.   :0.0000   Min.   : 1.000  \n 1st Qu.: 0.000   1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.: 6.000  \n Median : 0.000   Median :0.0000   Median :0.0000   Median : 8.000  \n Mean   : 4.242   Mean   :0.1682   Mean   :0.4403   Mean   : 8.032  \n 3rd Qu.: 3.000   3rd Qu.:0.0000   3rd Qu.:1.0000   3rd Qu.:10.000  \n Max.   :30.000   Max.   :1.0000   Max.   :1.0000   Max.   :13.000  \n   Education        Income     \n Min.   :1.00   Min.   :1.000  \n 1st Qu.:4.00   1st Qu.:5.000  \n Median :5.00   Median :7.000  \n Mean   :5.05   Mean   :6.054  \n 3rd Qu.:6.00   3rd Qu.:8.000  \n Max.   :6.00   Max.   :8.000  \n\n\nWe need to factor many of these fields. I also like to change doubles to integers for appropriate numeric fields. I checked the summary() to confirm that categorical variables like Age do not have values outside of the known ranges.\n\n\nFirst, factoring the simple ones with only a 0/1, then the batch of larger categorical fields.\n\n#simple factors first\ndata &lt;- data |&gt; mutate(\n  Diabetes_binary = factor(Diabetes_binary,labels=c(\"not diabetic\",\"diabetic\")),\n  HighBP = factor(HighBP,labels=c(\"no high blood pressure\",\"high blood pressure\")),\n  HighChol = factor(HighChol,labels=c(\"no high cholesterol\",\"high cholesterol\")),\n  CholCheck = factor(CholCheck,labels=c(\"no recent cholesterol check\",\"recent cholesterol check\")),\n  Smoker = factor(Smoker,labels=c(\"non-smoker\",\"smoker\")),\n  Stroke = factor(Stroke,labels=c(\"no stroke\",\"stroke\")),\n  HeartDiseaseorAttack = factor(HeartDiseaseorAttack,labels=c(\"no heart problems CHD/MI\",\"heart problems CHD/MI\")),\n  PhysActivity = factor(PhysActivity,labels=c(\"no physical activity\",\"physical activity\")),\n  Fruits = factor(Fruits,labels=c(\"no fruits\",\"fruits\")),\n  Veggies = factor(Veggies,labels=c(\"no vegetables\",\"vegetables\")),\n  HvyAlcoholConsump = factor(HvyAlcoholConsump,labels=c(\"no heavy alcohol\",\"heavy alcohol\")),\n  AnyHealthcare = factor(AnyHealthcare,labels=c(\"no healthcare\",\"healthcare\")),\n  NoDocbcCost = factor(NoDocbcCost,labels=c(\"not avoided doctor for cost\",\"avoided doctor for cost\")),\n  DiffWalk = factor(DiffWalk,labels=c(\"no walking difficulty\",\"walking difficulty\")),\n  Sex = factor(Sex,labels=c(\"female\",\"male\"))\n)\n\n#larger categories\ndata &lt;- data |&gt; mutate(\n  GenHlth = factor(GenHlth,labels=c(\"excellent\",\"very good\",\"good\",\"fair\",\"poor\")),\n  Age = factor(Age,labels=c(\n    \"18-24\",\n    \"25-29\",\n    \"30-34\",\n    \"35-39\",\n    \"40-44\",\n    \"45-49\",\n    \"50-54\",\n    \"55-59\",\n    \"60-64\",\n    \"65-69\",\n    \"70-74\",\n    \"75-79\",\n    \"80+\")),\n  Education = factor(Education,labels=c(\n    \"Never attended school or only kindergarten\",\n    \"Grades 1-8 (Elementary)\",\n    \"Grades 9-11 (Some high school)\",\n    \"Grades 12 or GED (High school graduate)\",\n    \"College 1-3 years (Some college or technical school\",\n    \"College 4+ years (College graduate)\")),\n  Income = factor(Income,labels=c(\n    \"[ - $10k)\",\n    \"[$10k - $15k)\",\n    \"[$15k - $20k)\",\n    \"[$20k - $25k)\",\n    \"[$25k - $35k)\",\n    \"[$35k - $50k)\",\n    \"[$50k - $75k)\",\n    \"[$75k - ]\"))\n)\n\n\n\n\nTransitioning from double to integers where needed. Checking values to confirm integers appropriate before switch.\n\n#checking results for integer reasonableness\nunique(data$BMI)\n\n [1] 40 25 28 27 24 30 34 26 33 21 23 22 38 32 37 31 29 20 35 45 39 19 47 18 36\n[26] 43 55 49 42 17 16 41 44 50 59 48 52 46 54 57 53 14 15 51 58 63 61 56 74 62\n[51] 64 66 73 85 60 67 65 70 82 79 92 68 72 88 96 13 81 71 75 12 77 69 76 87 89\n[76] 84 95 98 91 86 83 80 90 78\n\nunique(data$MentHlth)\n\n [1] 18  0 30  3  5 15 10  6 20  2 25  1  4  7  8 21 14 26 29 16 28 11 12 24 17\n[26] 13 27 19 22  9 23\n\nunique(data$PhysHlth)\n\n [1] 15  0 30  2 14 28  7 20  3 10  1  5 17  4 19  6 12 25 27 21 22  8 29 24  9\n[26] 16 18 23 13 26 11\n\n#convert doubles to ints\ndata &lt;- data |&gt; mutate(\n  BMI = as.integer(BMI),\n  MentHlth = as.integer(MentHlth),\n  PhysHlth = as.integer(PhysHlth)\n)\n\nstr(data)\n\ntibble [253,680 × 22] (S3: tbl_df/tbl/data.frame)\n $ Diabetes_binary     : Factor w/ 2 levels \"not diabetic\",..: 1 1 1 1 1 1 1 1 2 1 ...\n $ HighBP              : Factor w/ 2 levels \"no high blood pressure\",..: 2 1 2 2 2 2 2 2 2 1 ...\n $ HighChol            : Factor w/ 2 levels \"no high cholesterol\",..: 2 1 2 1 2 2 1 2 2 1 ...\n $ CholCheck           : Factor w/ 2 levels \"no recent cholesterol check\",..: 2 1 2 2 2 2 2 2 2 2 ...\n $ BMI                 : int [1:253680] 40 25 28 27 24 25 30 25 30 24 ...\n $ Smoker              : Factor w/ 2 levels \"non-smoker\",\"smoker\": 2 2 1 1 1 2 2 2 2 1 ...\n $ Stroke              : Factor w/ 2 levels \"no stroke\",\"stroke\": 1 1 1 1 1 1 1 1 1 1 ...\n $ HeartDiseaseorAttack: Factor w/ 2 levels \"no heart problems CHD/MI\",..: 1 1 1 1 1 1 1 1 2 1 ...\n $ PhysActivity        : Factor w/ 2 levels \"no physical activity\",..: 1 2 1 2 2 2 1 2 1 1 ...\n $ Fruits              : Factor w/ 2 levels \"no fruits\",\"fruits\": 1 1 2 2 2 2 1 1 2 1 ...\n $ Veggies             : Factor w/ 2 levels \"no vegetables\",..: 2 1 1 2 2 2 1 2 2 2 ...\n $ HvyAlcoholConsump   : Factor w/ 2 levels \"no heavy alcohol\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ AnyHealthcare       : Factor w/ 2 levels \"no healthcare\",..: 2 1 2 2 2 2 2 2 2 2 ...\n $ NoDocbcCost         : Factor w/ 2 levels \"not avoided doctor for cost\",..: 1 2 2 1 1 1 1 1 1 1 ...\n $ GenHlth             : Factor w/ 5 levels \"excellent\",\"very good\",..: 5 3 5 2 2 2 3 3 5 2 ...\n $ MentHlth            : int [1:253680] 18 0 30 0 3 0 0 0 30 0 ...\n $ PhysHlth            : int [1:253680] 15 0 30 0 0 2 14 0 30 0 ...\n $ DiffWalk            : Factor w/ 2 levels \"no walking difficulty\",..: 2 1 2 1 1 1 1 2 2 1 ...\n $ Sex                 : Factor w/ 2 levels \"female\",\"male\": 1 1 1 1 1 2 1 1 1 2 ...\n $ Age                 : Factor w/ 13 levels \"18-24\",\"25-29\",..: 9 7 9 11 11 10 9 11 9 8 ...\n $ Education           : Factor w/ 6 levels \"Never attended school or only kindergarten\",..: 4 6 4 3 5 6 6 4 5 4 ...\n $ Income              : Factor w/ 8 levels \"[ - $10k)\",\"[$10k - $15k)\",..: 3 1 8 6 4 8 7 4 1 3 ...\n\n\n\n\n\n\nMaking a few exploratory charts and plots, to increase understanding of the data and explore hunches and questions.\n\n\nThis section explores a few categorical variables with contingency tables and bar plots.\nWhat is our distribution of failures and successes (Diabetes_binary)?\n\ndata |&gt; \n  group_by(Diabetes_binary) |&gt;\n  summarize(count = n())\n\n# A tibble: 2 × 2\n  Diabetes_binary  count\n  &lt;fct&gt;            &lt;int&gt;\n1 not diabetic    218334\n2 diabetic         35346\n\n\nAbout 7:1 non-diabetic vs diabetic, with satisfactory sample sizes.\nLet’s explore the sex and age makeups. I’m switching to plots because I find the tabular, numeric contingency data to be less informative for exploration.\n\ng &lt;- data |&gt;\n  ggplot(\n    aes(\n      x=Age\n    )\n  ) +\n  labs(\n    title=\"Age Group Representation\"\n  ) +\n  geom_bar(\n    \n  )\ng\n\n\n\n\n\n\n\n\nMost in their 50-60s, generally older subjects.\n\ng &lt;- data |&gt;\n  ggplot(\n    aes(\n      x=Age,\n      fill=Sex\n    )\n  ) +\n  labs(\n    title=\"Age Group Representation by Sex\"\n  ) +\n  geom_bar(\n\n  )\ng\n\n\n\n\n\n\n\n\nReasonably equal makeup of men and women across age groups. How about the same faceted across income levels?\n\ng &lt;- data |&gt;\n  ggplot(\n    aes(\n      x=Age,\n      fill=Sex\n    )\n  ) +\n  labs(\n    title=\"Age Group Representation by Sex faceted by Income\",\n    x=''\n  ) +\n  geom_bar(\n\n  ) +\n  facet_grid(\n    . ~ Income\n  ) +\n  theme(\n    axis.text.x=element_blank()\n  )\ng\n\n\n\n\n\n\n\n\nOur survey data leans heavily on middle class+ respondents. It’s worth recalling this as interpretations are made in aggregate, either to temper them with a known skew toward high earners or else grouped by income levels as a known strata of interest. Then again, this variable may have no significant bearing on the predictive model, in which case this point is unnecessary.\nLet’s adjust this to see diabetic state by income level.\n\ng &lt;- data |&gt;\n  ggplot(\n    aes(\n      x=Age,\n      fill=Diabetes_binary\n    )\n  ) +\n  labs(\n    title=\"Age Group Representation by Diabetes state faceted by Income\",\n    x=''\n  ) +\n  geom_bar(\n\n  ) +\n  facet_grid(\n    . ~ Income\n  ) +\n  theme(\n    axis.text.x=element_blank()\n  )\ng\n\n\n\n\n\n\n\n\nAt a glance, I think the proportion of diabetic respondents is higher for lower income levels. Interesting but no takeaway right now.\n\n\n\nWe have three numeric fields to explore: BMI, Mental Health, and Physical Health. The encoding here is a little confusing, where higher numbers indicate more detrimental values of BMI, mental, or physical health. The two health fields are a count of problems experienced in the last X days.\nFirst, let’s check density charts for Diabetic and non-Diabetic fills.\n\ng &lt;- data |&gt;\n  ggplot(\n    aes(\n      x=BMI,\n      fill=Diabetes_binary\n    )\n  ) +\n  labs(\n    title=\"BMI density chart with Diabetes state\",\n  ) +\n  geom_density(\n    alpha=0.5\n    #bindwidth=11\n  ) \ng\n\n\n\n\n\n\n\n\nThat is staggeringly clear, a strong predictor.\n\ng &lt;- data |&gt; ggplot()\ng +\n  aes(\n    x=MentHlth,\n    fill=Diabetes_binary\n  ) +\n  labs(\n    title=\"Mental Health Incidents Histogram with Diabetes state\",\n  ) +\n  geom_histogram(\n    alpha=0.5,\n    binwidth=2\n  ) \n\n\n\n\n\n\n\n\n\ng &lt;- data |&gt; ggplot()\ng +\n  aes(\n    x=PhysHlth,\n    fill=Diabetes_binary\n  ) +\n  labs(\n    title=\"Physical Health Incidents Histogram with Diabetes state\",\n  ) +\n  geom_histogram(\n    alpha=0.5,\n    binwidth=2\n  ) \n\n\n\n\n\n\n\n\nThese health numeric variables are skewed heavily right, with most respondents reporting 0. I don’t expect much to come from it but let’s check summaries and correlation too.\n\ndata |&gt; \n  select(BMI,MentHlth,PhysHlth) |&gt;\n  summary()\n\n      BMI           MentHlth         PhysHlth     \n Min.   :12.00   Min.   : 0.000   Min.   : 0.000  \n 1st Qu.:24.00   1st Qu.: 0.000   1st Qu.: 0.000  \n Median :27.00   Median : 0.000   Median : 0.000  \n Mean   :28.38   Mean   : 3.185   Mean   : 4.242  \n 3rd Qu.:31.00   3rd Qu.: 2.000   3rd Qu.: 3.000  \n Max.   :98.00   Max.   :30.000   Max.   :30.000  \n\n\n\ncor(data[sapply(data,is.numeric)]) \n\n                BMI   MentHlth  PhysHlth\nBMI      1.00000000 0.08531016 0.1211411\nMentHlth 0.08531016 1.00000000 0.3536189\nPhysHlth 0.12114111 0.35361887 1.0000000\n\n\nThe summary stats confirm the takes noted above. Stronger correlation between mental health incident days and physical health incident days, which sounds reasonable. No need to explore a scatterplot here, for these few and clear numeric variables.\nInstead, let’s check a boxplot of the numeric fields across categories including the response variable.\n\ng &lt;- data |&gt; ggplot()\ng +\n  aes(\n\n  ) +\n  labs(\n    title=\"BMI over Diabetes state by Sex\",\n  ) +\n  geom_boxplot(\n    aes(\n      x=BMI,\n      fill=Diabetes_binary\n      )  \n    ) +\n  facet_grid( Sex~.)\n\n\n\n\n\n\n\n\nSo, higher BMIs link with diabetic state in both sexes. Also, interesting to see the range of BMI for diabetic females is a little wider than that of males.\nDone with EDA here. I think many of the predictors may relate to the response variable, so I’ll proceed to modeling to understand more about the stronger predictor variables, then perhaps study further. I’ll save and load the updated tibble with my data for processing in the Modeling page.\nClick here for the Modeling Page\n\n#here, just saving data frame for use in Modeling\nsave(data,file=\"data.RData\")"
  },
  {
    "objectID": "Modeling.html",
    "href": "Modeling.html",
    "title": "Modeling",
    "section": "",
    "text": "This is the continuation of the project introduced in EDA.qmd.\n\n\nThere are six components to this project.\n\nEDA - quarto file with EDA (this file)\nModeling - quarto file to select the best model using tidymodels\nAPI - R file fitting the model and defining API structure\nDockerfile - for building the Docker image\n.tar - Docker image\nDemo - video showing me demonstrating my Docker container\n\n\n\n\nFor rendering, I need to reload libraries. Also, I’m just sharing my data frame from the EDA file and loading it here, rather than redoing the EDA code.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tidymodels)\n\nWarning: package 'tidymodels' was built under R version 4.4.2\n\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.2.0 ──\n✔ broom        1.0.6     ✔ rsample      1.2.1\n✔ dials        1.3.0     ✔ tune         1.2.1\n✔ infer        1.0.7     ✔ workflows    1.1.4\n✔ modeldata    1.4.0     ✔ workflowsets 1.1.0\n✔ parsnip      1.2.1     ✔ yardstick    1.3.1\n✔ recipes      1.1.0     \n\n\nWarning: package 'dials' was built under R version 4.4.2\n\n\nWarning: package 'infer' was built under R version 4.4.2\n\n\nWarning: package 'modeldata' was built under R version 4.4.2\n\n\nWarning: package 'parsnip' was built under R version 4.4.2\n\n\nWarning: package 'recipes' was built under R version 4.4.2\n\n\nWarning: package 'rsample' was built under R version 4.4.2\n\n\nWarning: package 'tune' was built under R version 4.4.2\n\n\nWarning: package 'workflows' was built under R version 4.4.2\n\n\nWarning: package 'workflowsets' was built under R version 4.4.2\n\n\nWarning: package 'yardstick' was built under R version 4.4.2\n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Use tidymodels_prefer() to resolve common conflicts.\n\nload(\"data.RData\")"
  },
  {
    "objectID": "Modeling.html#project-introduction",
    "href": "Modeling.html#project-introduction",
    "title": "Modeling",
    "section": "",
    "text": "This is the continuation of the project introduced in EDA.qmd.\n\n\nThere are six components to this project.\n\nEDA - quarto file with EDA (this file)\nModeling - quarto file to select the best model using tidymodels\nAPI - R file fitting the model and defining API structure\nDockerfile - for building the Docker image\n.tar - Docker image\nDemo - video showing me demonstrating my Docker container\n\n\n\n\nFor rendering, I need to reload libraries. Also, I’m just sharing my data frame from the EDA file and loading it here, rather than redoing the EDA code.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tidymodels)\n\nWarning: package 'tidymodels' was built under R version 4.4.2\n\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.2.0 ──\n✔ broom        1.0.6     ✔ rsample      1.2.1\n✔ dials        1.3.0     ✔ tune         1.2.1\n✔ infer        1.0.7     ✔ workflows    1.1.4\n✔ modeldata    1.4.0     ✔ workflowsets 1.1.0\n✔ parsnip      1.2.1     ✔ yardstick    1.3.1\n✔ recipes      1.1.0     \n\n\nWarning: package 'dials' was built under R version 4.4.2\n\n\nWarning: package 'infer' was built under R version 4.4.2\n\n\nWarning: package 'modeldata' was built under R version 4.4.2\n\n\nWarning: package 'parsnip' was built under R version 4.4.2\n\n\nWarning: package 'recipes' was built under R version 4.4.2\n\n\nWarning: package 'rsample' was built under R version 4.4.2\n\n\nWarning: package 'tune' was built under R version 4.4.2\n\n\nWarning: package 'workflows' was built under R version 4.4.2\n\n\nWarning: package 'workflowsets' was built under R version 4.4.2\n\n\nWarning: package 'yardstick' was built under R version 4.4.2\n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Use tidymodels_prefer() to resolve common conflicts.\n\nload(\"data.RData\")"
  },
  {
    "objectID": "Modeling.html#modeling",
    "href": "Modeling.html#modeling",
    "title": "Modeling",
    "section": "Modeling",
    "text": "Modeling\nThis Quarto file continues into the Modeling step. We need to make a training/test split (70/30) and include a seed. We will predict the diabetes response variable using different models via tidymodels, evaluating with 5CV log-loss as metric. I’m not stratifying the split.\n\nData split\nI’m using a 70% split for a training subset of the data. Here, I’m also specifying the seed as 1.\n\nset.seed(1)\n\n#for debugging\n#data = filter(data,row_number()&lt;=200)\n\nsplit &lt;- initial_split(data, prop = 0.7)\ntrain &lt;- training(split)\ntest &lt;- testing(split)\ntrain_5cv &lt;- vfold_cv(train, 5)\n\n#adding another copy for a first, smaller pass to find interesting variables for full modeling\nfirst_data &lt;- sample_n(data, 20000)\n#first_data &lt;- sample_n(data, 200) #debug only\nfirst_split &lt;- initial_split(first_data, prop = 0.7)\nfirst_train &lt;- training(first_split)\nfirst_test &lt;- testing(first_split)\nfirst_train_5cv &lt;- vfold_cv(first_train, 5)\n\n\n\nClassification Tree\nThe first model type used here is a classification tree. As the tree builds, at each level the best (per our metric) predictor and its value are used to separate into two subsequent branches of the tree: is x &gt; 0.5? Yes - path A; No - path B. Then recursively the same occurs at each subsequent branch, up to some number of levels of the tree. This is not an optimal solution, as it can be influenced significantly by the data grabbed in the training set, but it is fairly intuitive to interpret as a series of sequential yes/no decisions that land either on a success or failure (most prevalent for training data) at the bottom of the tree.\nWe will tune the number of levels and any other tunable parameters, using 5Fold CV as mentioned earlier.\n\nRecipe definition\nNot much needs to happen here, aside from creating numerous dummy variables. I will also normalize my few numeric variables. I will start first with a 21 predictor set for a subset (20000), to attempt to see the predictive strength of each input. Then, I’ll choose some smaller number of the more interesting variables to use for the rest of the work (including a re-evaluation of this model).\n\n#first, adjusting\nfirst_recipe &lt;- recipe(Diabetes_binary ~ ., data = first_train) |&gt;\n  \n  #normalize numerics\n  step_normalize(\n    all_numeric(),\n    -all_outcomes()\n    ) |&gt;\n  \n  #dummy vars for categorical items\n  step_dummy(\n    all_factor_predictors()\n    )\n\nfirst_peek &lt;- head(first_recipe|&gt;prep()|&gt;bake(head(first_train)))\n\n\n\nModel tuning\nNow, defining the model characteristics, workflow, and tuning.\n\n#model\nfirst_model_classtree &lt;- \n  decision_tree(\n    tree_depth = tune(),\n    min_n = tune(),\n    cost_complexity = tune()\n    ) |&gt;\n  set_engine(\"rpart\")|&gt;#,importance=\"impurity\") |&gt;\n  set_mode(\"classification\")\n\n#workflow\nfirst_workflow_classtree &lt;- workflow() |&gt;\n  add_recipe(first_recipe) |&gt;\n  add_model(first_model_classtree)\n\n#grid config\nfirst_grid_classtree &lt;- grid_regular(\n  cost_complexity(),\n  tree_depth(),\n  min_n(),\n  levels = c(2, 2, 2)\n  )\n\n#tuning setup\nfirst_tune_grid_classtree &lt;- first_workflow_classtree |&gt; \n  tune_grid(\n    resamples = first_train_5cv,\n    grid = first_grid_classtree,\n    metrics = metric_set(mn_log_loss)\n    )\n\nfirst_tune_grid_classtree |&gt;\n  collect_metrics()\n\n# A tibble: 8 × 9\n  cost_complexity tree_depth min_n .metric     .estimator  mean     n std_err\n            &lt;dbl&gt;      &lt;int&gt; &lt;int&gt; &lt;chr&gt;       &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;\n1    0.0000000001          1     2 mn_log_loss binary     0.398     5 0.00274\n2    0.1                   1     2 mn_log_loss binary     0.398     5 0.00274\n3    0.0000000001         15     2 mn_log_loss binary     4.83      5 0.0547 \n4    0.1                  15     2 mn_log_loss binary     0.398     5 0.00274\n5    0.0000000001          1    40 mn_log_loss binary     0.398     5 0.00274\n6    0.1                   1    40 mn_log_loss binary     0.398     5 0.00274\n7    0.0000000001         15    40 mn_log_loss binary     0.351     5 0.00447\n8    0.1                  15    40 mn_log_loss binary     0.398     5 0.00274\n# ℹ 1 more variable: .config &lt;chr&gt;\n\n\nContinuing with tuning accordingly for this first, small pass, and then displaying importance for each predictor.\n\nfirst_tune_classtree &lt;- first_tune_grid_classtree |&gt;\n  select_best(metric = \"mn_log_loss\")\n\nfirst_workflow_classtree &lt;- first_workflow_classtree |&gt;\n  finalize_workflow(first_tune_classtree)\nfirst_fit_classtree &lt;- first_workflow_classtree |&gt;\n  fit(first_train)\n\nfirst_importance_classtree &lt;- extract_fit_engine(first_fit_classtree)$variable.importance\ntibble(term=names(first_importance_classtree),value=first_importance_classtree) |&gt;\n  arrange(value) |&gt;\n  mutate(term = factor(term, levels = term)) |&gt;\n  ggplot(aes(x = term, y = value)) +\n  geom_bar(stat =\"identity\") +\n  coord_flip()\n\n\n\n\n\n\n\n\nWow, it is so frustrating to get all the syntax just right to work, in practice! At least this chart is clear in direction! I want to study the more important variables, such as those in the top 10 here. I’ll choose some of the top and one or two low-importance items that I had expected to relate strongly. These need renaming, too.\n\n#overwriting recipe with reference to full scale training dataset\nrecipe &lt;- recipe(Diabetes_binary ~ ., data = train) |&gt;\n  \n  #stripping out many columns - step_rm NOT step_select\n  step_rm(\n    CholCheck,\n    Smoker,\n    Stroke,\n    PhysActivity,\n    Fruits,\n    HvyAlcoholConsump,\n    AnyHealthcare,\n    NoDocbcCost,\n    GenHlth,\n    Sex,\n    Age,\n    Education,\n    Income\n  ) |&gt;\n  \n  #normalize numerics\n  step_normalize(\n    all_numeric(),\n    -all_outcomes()\n    ) |&gt;\n  \n  #dummy vars for categorical items\n  step_dummy(\n    all_factor_predictors()\n  ) |&gt;\n\n  #rename attempt here, dont touch outcome\n  step_rename(\n    high_bp = HighBP_high.blood.pressure,\n    bmi = BMI,\n    difficulty_walking = DiffWalk_walking.difficulty,\n    high_cholesterol = HighChol_high.cholesterol,\n    heart_problems = HeartDiseaseorAttack_heart.problems.CHD.MI,\n    vegetables = Veggies_vegetables,\n    physical_health_problems = PhysHlth,\n    mental_health_problems = MentHlth\n  )\n\n#checking results look ok\npeek &lt;- head(recipe|&gt;prep()|&gt;bake(head(train)))\npeek\n\n# A tibble: 6 × 9\n     bmi mental_health_problems physical_health_problems Diabetes_binary high_bp\n   &lt;dbl&gt;                  &lt;dbl&gt;                    &lt;dbl&gt; &lt;fct&gt;             &lt;dbl&gt;\n1 -0.664                 -0.430                  -0.487  not diabetic          1\n2 -0.360                 -0.430                   0.0870 not diabetic          1\n3 -0.815                 -0.430                  -0.487  not diabetic          0\n4 -0.512                 -0.430                  -0.487  diabetic              0\n5  0.398                 -0.430                  -0.487  not diabetic          1\n6 -0.360                 -0.430                   2.96   not diabetic          1\n# ℹ 4 more variables: high_cholesterol &lt;dbl&gt;, heart_problems &lt;dbl&gt;,\n#   vegetables &lt;dbl&gt;, difficulty_walking &lt;dbl&gt;\n\n\nLooks ok! Now, let’s build the proper classification tree model with 5Fold CV on our proper training samples.\n\n\nFull model tuning\n\n#model\nmodel_classtree &lt;- \n  decision_tree(\n    tree_depth = tune(),\n    min_n = tune(),\n    cost_complexity = tune()\n    ) |&gt;\n  set_engine(\"rpart\") |&gt;\n  set_mode(\"classification\")\n\n#workflow\nworkflow_classtree &lt;- workflow() |&gt;\n  add_recipe(recipe) |&gt;\n  add_model(model_classtree)\n\n#grid config\ngrid_classtree &lt;- grid_regular(\n  cost_complexity(),\n  tree_depth(c(2,15)), #min of 2 seems more sensible\n  min_n(c(10,100)), #I dont want min_n 2 as minimum for this giant dataset\n  levels = c(3, 3, 3)\n  )\n\n#tuning setup\ntune_grid_classtree &lt;- workflow_classtree |&gt; \n  tune_grid(\n    resamples = train_5cv,\n    grid = grid_classtree,\n    metrics = metric_set(mn_log_loss)\n    )\n\ntune_classtree &lt;- tune_grid_classtree |&gt; \n  select_best(metric = \"mn_log_loss\")\n\nworkflow_classtree &lt;- workflow_classtree |&gt;\n  finalize_workflow(tune_classtree)\nfit_classtree &lt;- workflow_classtree |&gt;\n  fit(train)\n\nfit_classtree |&gt; \n  extract_fit_engine() |&gt; \n  rpart.plot::rpart.plot(roundint=FALSE)\n\nWarning: labs do not fit even at cex 0.15, there may be some overplotting\n\n\n\n\n\n\n\n\n\nA pretty tree, though completely unreadable. The best tree_depth is around 8-15, based on various tuning runs.\n\n\n\nRandom Forest\nNow, let’s explore the random forest model family and find its best contender fit.\nThis family makes an ensemble of special trees and finds the average across them. As a regular classification tree is over-impacted by small changes to its training data, random forest models implement bootstrapping and further a random subset of predictors to create its ensemble. Bootstrapping, or creating new samples by selecting from the training data with replacement, helps to avoid the susceptibility to high variance driven by training selections; as we create a set of these, the average has lower variance overall. And the second adjustment is a random selection of predictor inputs, which helps decrease variance and identify possible better fits by minimizing oversized impact due to strong predictors. Again, by creating an ensemble group of models, we can average the results to find a model that will generally have lower variance than the weaker single tree method.\n\nFull model tuning\nHaving already done my first pass to decide on interesting predictors, as part of the first model section, here I am conducting only a standard tuning process. Again, I’m tuning all possible variables, because I have such little experience.\n\n#model definition\nmodel_randomforest &lt;- rand_forest(\n  mtry = tune(),\n  trees = tune(),\n  min_n = tune()\n  ) |&gt;\n  set_engine(\"ranger\",importance=\"impurity\") |&gt;\n  set_mode(\"classification\")\n\n#workflow using same prior model recipe\nworkflow_randomforest &lt;- workflow() |&gt;\n  add_recipe(recipe) |&gt;\n  add_model(model_randomforest)\n\n#tuning prep\ngrid_randomforest &lt;- grid_regular(\n  mtry(c(2,6)), #choosing min over 1 and max less than full\n  trees(c(100,2000)), #some variation but not too low\n  min_n(c(10,100)), #I dont want min_n 2 as minimum for this giant dataset\n  levels = c(2, 3, 2)\n  )\n\n#run tuning\ntune_grid_randomforest &lt;- workflow_randomforest |&gt; \n  tune_grid(\n    resamples = train_5cv,\n    grid=grid_randomforest,\n    metrics = metric_set(mn_log_loss)\n    )\n\nWarning: package 'ranger' was built under R version 4.4.2\n\n#save best tuning per log-loss\ntune_randomforest &lt;- tune_grid_randomforest |&gt; select_best(metric=\"mn_log_loss\")\nworkflow_randomforest &lt;- workflow_randomforest |&gt;\n  finalize_workflow(tune_randomforest)\n\n#fit on full training data\nfit_randomforest &lt;- workflow_randomforest |&gt;\n  fit(train)\n\n\n\n\nModel selection\nNow, let’s compare the error of both models against our holdout test data and identify our best option!\n\nmetric_classtree &lt;- workflow_classtree |&gt;\n  last_fit(split,\n           metrics = metric_set(mn_log_loss)\n           ) |&gt;\n  collect_metrics()\n\nmetric_randomforest &lt;- workflow_randomforest |&gt;\n  last_fit(split,\n           metrics = metric_set(mn_log_loss)\n           ) |&gt;\n  collect_metrics()\n\nmetric_classtree\n\n# A tibble: 1 × 4\n  .metric     .estimator .estimate .config             \n  &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 mn_log_loss binary         0.342 Preprocessor1_Model1\n\nmetric_randomforest\n\n# A tibble: 1 × 4\n  .metric     .estimator .estimate .config             \n  &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 mn_log_loss binary         0.336 Preprocessor1_Model1\n\n\nOur best performing model is the random forest model. Let’s save it to a file, to reference in our API.\n\nsave(workflow_classtree,file=\"workflow_classtree.rda\")\nsave(workflow_randomforest,file=\"workflow_randomforest.rda\")"
  }
]